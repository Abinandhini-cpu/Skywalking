# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This will parse a textual representation of a duration. The formats
# accepted are based on the ISO-8601 duration format {@code PnDTnHnMn.nS}
# with days considered to be exactly 24 hours.
# <p>
# Examples:
# <pre>
#    "PT20.345S" -- parses as "20.345 seconds"
#    "PT15M"     -- parses as "15 minutes" (where a minute is 60 seconds)
#    "PT10H"     -- parses as "10 hours" (where an hour is 3600 seconds)
#    "P2D"       -- parses as "2 days" (where a day is 24 hours or 86400 seconds)
#    "P2DT3H4M"  -- parses as "2 days, 3 hours and 4 minutes"
#    "P-6H3M"    -- parses as "-6 hours and +3 minutes"
#    "-P6H3M"    -- parses as "-6 hours and -3 minutes"
#    "-P-6H+3M"  -- parses as "+6 hours and -3 minutes"
# </pre>
filter: "{ tags -> tags.job_name == 'bookkeeper-monitoring' }" # The OpenTelemetry job name
expSuffix: tag({tags -> tags.cluster = 'bookkeeper::' + tags.cluster}).instance(['cluster'], ['bookie'], Layer.PULSAR)
metricPrefix: meter_bookkeeper
metricsRules:

  - name: server_status
    exp: bookie_SERVER_STATUS.sum(['cluster','bookie'])

  - name: add_entry_count
    exp: bookkeeper_server_ADD_ENTRY_count.sum(['cluster','bookie'])

  - name: read_entry_count
    exp: bookkeeper_server_READ_ENTRY_count.sum(['cluster','bookie'])

  - name: write_bytes
    exp: bookie_WRITE_BYTES.sum(['cluster','bookie'])

  - name: read_bytes
    exp: bookie_READ_BYTES.sum(['cluster','bookie'])

  - name: add_entry_request_latency
    exp: bookkeeper_server_ADD_ENTRY_REQUEST.sum(['cluster','bookie'])

  - name: read_entry_request_latency
    exp: bookkeeper_server_READ_ENTRY_REQUEST.sum(['cluster','bookie'])

  - name: bookie_read_threadpool_task_queued_time
    exp: bookkeeper_server_BookieReadThreadPool_task_queued.sum(['cluster','bookie'])

  - name: bookie_read_threadpool_task_execution_time
    exp: bookkeeper_server_BookieReadThreadPool_task_execution.sum(['cluster','bookie'])

  - name: journal_sync_count
    exp: bookie_journal_JOURNAL_SYNC_count.sum(['cluster','bookie'])

  - name: journal_queue_size
    exp: bookie_journal_JOURNAL_QUEUE_SIZE.sum(['cluster','bookie'])

  - name: journal_force_write_queue_size
    exp: bookie_journal_JOURNAL_FORCE_WRITE_QUEUE_SIZE.sum(['cluster','bookie'])

  - name: journal_cb_queue_size
    exp: bookie_journal_JOURNAL_CB_QUEUE_SIZE.sum(['cluster','bookie'])

  - name: journal_add_entry_latency
    exp: bookie_journal_JOURNAL_ADD_ENTRY.sum(['cluster','bookie'])

  - name: journal_sync_latency
    exp: bookie_journal_JOURNAL_SYNC.sum(['cluster','bookie'])

  - name: journal_creation_latency
    exp: bookie_journal_JOURNAL_CREATION_LATENCY.sum(['cluster','bookie'])

  - name: ledgers_count
    exp: bookie_ledgers_count.sum(['cluster','bookie'])

  - name: entries_count
    exp: bookie_entries_count.sum(['cluster','bookie'])

  - name: write_cache_size
    exp: bookie_write_cache_size.sum(['cluster','bookie'])

  - name: read_cache_size
    exp: bookie_read_cache_size.sum(['cluster','bookie'])

  - name: deleted_ledger_count
    exp: bookie_DELETED_LEDGER_COUNT.sum(['cluster','bookie'])

  - name: ledger_writable_dirs
    exp: bookie_ledger_writable_dirs.sum(['cluster','bookie'])

  - name: bookie_flush_latency
    exp: bookie_flush.sum(['cluster','bookie'])

  - name: throttled_write_requests
    exp: bookie_throttled_write_requests.sum(['cluster','bookie'])